---
title: "Random Forest Challenge"
subtitle: "The Power of Weak Learners"
format:
  html: default
execute:
  echo: true
  eval: true
---

# ðŸŒ² Random Forest Challenge - The Power of Weak Learners

### R

```{r}
#| label: load-and-model-r
#| echo: false
#| message: false
#| warning: false

# Load libraries
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(randomForest))

# Load data
sales_data <- read.csv("https://raw.githubusercontent.com/flyaflya/buad442Fall2025/refs/heads/main/datasets/salesPriceData.csv")

# Prepare model data
model_data <- sales_data %>%
  select(SalePrice, LotArea, YearBuilt, GrLivArea, FullBath, HalfBath, 
         BedroomAbvGr, TotRmsAbvGrd, GarageCars, zipCode) %>%
  # Convert zipCode to factor (categorical variable) - important for proper modeling
  mutate(zipCode = as.factor(zipCode)) %>%
  na.omit()

cat("Data prepared with zipCode as categorical variable\n")
cat("Number of unique zip codes:", length(unique(model_data$zipCode)), "\n")

# Split data
set.seed(123)
train_indices <- sample(1:nrow(model_data), 0.8 * nrow(model_data))
train_data <- model_data[train_indices, ]
test_data <- model_data[-train_indices, ]

# Build random forests with different numbers of trees (with corrected categorical zipCode)
rf_1 <- randomForest(SalePrice ~ ., data = train_data, ntree = 1, mtry = 3, seed = 123)
rf_5 <- randomForest(SalePrice ~ ., data = train_data, ntree = 5, mtry = 3, seed = 123)
rf_25 <- randomForest(SalePrice ~ ., data = train_data, ntree = 25, mtry = 3, seed = 123)
rf_100 <- randomForest(SalePrice ~ ., data = train_data, ntree = 100, mtry = 3, seed = 123)
rf_500 <- randomForest(SalePrice ~ ., data = train_data, ntree = 500, mtry = 3, seed = 123)
rf_1000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 1000, mtry = 3, seed = 123)
rf_2000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 2000, mtry = 3, seed = 123)
rf_5000 <- randomForest(SalePrice ~ ., data = train_data, ntree = 5000, mtry = 3, seed = 123)
```

:::

## Results: The Power of Ensemble Learning

Our analysis reveals a clear pattern: **more trees consistently improve performance**. Let's examine the results and understand why this happens.

### Performance Trends

::: panel-tabset
### R

```{r}
#| label: performance-comparison-r
#| echo: false
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 6

# Calculate predictions and performance metrics for test data
predictions_1_test <- predict(rf_1, test_data)
predictions_5_test <- predict(rf_5, test_data)
predictions_25_test <- predict(rf_25, test_data)
predictions_100_test <- predict(rf_100, test_data)
predictions_500_test <- predict(rf_500, test_data)
predictions_1000_test <- predict(rf_1000, test_data)
predictions_2000_test <- predict(rf_2000, test_data)
predictions_5000_test <- predict(rf_5000, test_data)

# Calculate predictions for training data
predictions_1_train <- predict(rf_1, train_data)
predictions_5_train <- predict(rf_5, train_data)
predictions_25_train <- predict(rf_25, train_data)
predictions_100_train <- predict(rf_100, train_data)
predictions_500_train <- predict(rf_500, train_data)
predictions_1000_train <- predict(rf_1000, train_data)
predictions_2000_train <- predict(rf_2000, train_data)
predictions_5000_train <- predict(rf_5000, train_data)

# Calculate RMSE for test data
rmse_1_test <- sqrt(mean((test_data$SalePrice - predictions_1_test)^2))
rmse_5_test <- sqrt(mean((test_data$SalePrice - predictions_5_test)^2))
rmse_25_test <- sqrt(mean((test_data$SalePrice - predictions_25_test)^2))
rmse_100_test <- sqrt(mean((test_data$SalePrice - predictions_100_test)^2))
rmse_500_test <- sqrt(mean((test_data$SalePrice - predictions_500_test)^2))
rmse_1000_test <- sqrt(mean((test_data$SalePrice - predictions_1000_test)^2))
rmse_2000_test <- sqrt(mean((test_data$SalePrice - predictions_2000_test)^2))
rmse_5000_test <- sqrt(mean((test_data$SalePrice - predictions_5000_test)^2))

# Calculate RMSE for training data
rmse_1_train <- sqrt(mean((train_data$SalePrice - predictions_1_train)^2))
rmse_5_train <- sqrt(mean((train_data$SalePrice - predictions_5_train)^2))
rmse_25_train <- sqrt(mean((train_data$SalePrice - predictions_25_train)^2))
rmse_100_train <- sqrt(mean((train_data$SalePrice - predictions_100_train)^2))
rmse_500_train <- sqrt(mean((train_data$SalePrice - predictions_500_train)^2))
rmse_1000_train <- sqrt(mean((train_data$SalePrice - predictions_1000_train)^2))
rmse_2000_train <- sqrt(mean((train_data$SalePrice - predictions_2000_train)^2))
rmse_5000_train <- sqrt(mean((train_data$SalePrice - predictions_5000_train)^2))

# Calculate R-squared
r2_1 <- 1 - sum((test_data$SalePrice - predictions_1_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_5 <- 1 - sum((test_data$SalePrice - predictions_5_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_25 <- 1 - sum((test_data$SalePrice - predictions_25_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_100 <- 1 - sum((test_data$SalePrice - predictions_100_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_500 <- 1 - sum((test_data$SalePrice - predictions_500_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_1000 <- 1 - sum((test_data$SalePrice - predictions_1000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_2000 <- 1 - sum((test_data$SalePrice - predictions_2000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
r2_5000 <- 1 - sum((test_data$SalePrice - predictions_5000_test)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)

# Create performance comparison
performance_df <- data.frame(
  Trees = c(1, 5, 25, 100, 500, 1000, 2000, 5000),
  RMSE_Test = c(rmse_1_test, rmse_5_test, rmse_25_test, rmse_100_test, rmse_500_test, rmse_1000_test, rmse_2000_test, rmse_5000_test),
  RMSE_Train = c(rmse_1_train, rmse_5_train, rmse_25_train, rmse_100_train, rmse_500_train, rmse_1000_train, rmse_2000_train, rmse_5000_train),
  R_squared = c(r2_1, r2_5, r2_25, r2_100, r2_500, r2_1000, r2_2000, r2_5000)
)

print(performance_df)
```
:::

### 1. The Power of More Trees Visualization

```{r}
#| label: power-of-trees-viz
#| echo: false
#| fig-width: 12
#| fig-height: 8
#| message: false
#| warning: false

# Load additional libraries for plotting
library(ggplot2)
library(gridExtra)

# Create RMSE plot
rmse_plot <- ggplot(performance_df, aes(x = Trees)) +
  geom_line(aes(y = RMSE_Test, color = "Test Data"), size = 1.2) +
  geom_line(aes(y = RMSE_Train, color = "Training Data"), size = 1.2) +
  geom_point(aes(y = RMSE_Test, color = "Test Data"), size = 2.5) +
  geom_point(aes(y = RMSE_Train, color = "Training Data"), size = 2.5) +
  scale_x_log10(breaks = c(1, 5, 25, 100, 500, 1000, 2000, 5000)) +
  scale_color_manual(values = c("Test Data" = "#E31A1C", "Training Data" = "#1F78B4")) +
  labs(
    title = "RMSE vs Number of Trees in Random Forest",
    subtitle = "Lower RMSE indicates better predictive performance",
    x = "Number of Trees (Log Scale)",
    y = "Root Mean Square Error (RMSE)",
    color = "Dataset"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 12),
    legend.position = "bottom"
  )

# Create R-squared plot
r2_plot <- ggplot(performance_df, aes(x = Trees, y = R_squared)) +
  geom_line(color = "#2E8B57", size = 1.2) +
  geom_point(color = "#2E8B57", size = 2.5) +
  scale_x_log10(breaks = c(1, 5, 25, 100, 500, 1000, 2000, 5000)) +
  labs(
    title = "R-squared vs Number of Trees in Random Forest",
    subtitle = "Higher R-squared indicates better model fit",
    x = "Number of Trees (Log Scale)",
    y = "R-squared"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 12)
  )

# Combine plots
grid.arrange(rmse_plot, r2_plot, ncol = 1)
```

**Analysis of the Power of More Trees:**

The analysis shows that the biggest improvements happen early on, with test RMSE dropping by about \$15,000, or around 12 percent, when increasing from 1 to 5 trees. This demonstrates how combining several weak learners quickly boosts accuracy and captures more complex patterns. After about 100 trees, the performance gains become very small, with only about a \$2,000 (less than 2 percent) drop in RMSE between 100 and 5000 trees. This shows that adding more trees eventually brings diminishing returns, as the extra computational cost provides little benefit. The steady gap between training and test RMSE suggests that random forests continue to generalize well and avoid overfitting, even as the number of trees increases.

### 2. Overfitting Analysis: Decision Trees vs Random Forests

```{r}
#| label: overfitting-analysis
#| echo: false
#| fig-width: 14
#| fig-height: 8
#| message: false
#| warning: false

# Load required libraries
library(rpart)
library(rpart.plot)

# Create decision trees with different max depths
max_depths <- c(1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 15, 20)
dt_train_rmse <- numeric(length(max_depths))
dt_test_rmse <- numeric(length(max_depths))

for(i in 1:length(max_depths)) {
  # Create decision tree with specific max depth
  dt_model <- rpart(SalePrice ~ ., data = train_data, 
                   control = rpart.control(maxdepth = max_depths[i]))
  
  # Calculate predictions
  dt_train_pred <- predict(dt_model, train_data)
  dt_test_pred <- predict(dt_model, test_data)
  
  # Calculate RMSE
  dt_train_rmse[i] <- sqrt(mean((train_data$SalePrice - dt_train_pred)^2))
  dt_test_rmse[i] <- sqrt(mean((test_data$SalePrice - dt_test_pred)^2))
}

# Create data frame for decision trees
dt_performance <- data.frame(
  Complexity = max_depths,
  RMSE_Train = dt_train_rmse,
  RMSE_Test = dt_test_rmse,
  Model_Type = "Decision Trees"
)

# Create data frame for random forests (using existing performance_df)
rf_performance <- data.frame(
  Complexity = performance_df$Trees,
  RMSE_Train = performance_df$RMSE_Train,
  RMSE_Test = performance_df$RMSE_Test,
  Model_Type = "Random Forest"
)

# Combine data for plotting
combined_performance <- rbind(dt_performance, rf_performance)

# Create decision tree plot
dt_plot <- ggplot(dt_performance, aes(x = Complexity)) +
  geom_line(aes(y = RMSE_Train, color = "Training"), size = 1.2) +
  geom_line(aes(y = RMSE_Test, color = "Test"), size = 1.2) +
  geom_point(aes(y = RMSE_Train, color = "Training"), size = 2) +
  geom_point(aes(y = RMSE_Test, color = "Test"), size = 2) +
  scale_color_manual(values = c("Training" = "#1F78B4", "Test" = "#E31A1C")) +
  labs(
    title = "Decision Trees: Overfitting as Complexity Increases",
    subtitle = "Gap between training and test RMSE widens with more complex trees",
    x = "Maximum Tree Depth",
    y = "RMSE",
    color = "Dataset"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    plot.subtitle = element_text(size = 10),
    axis.title = element_text(size = 10),
    legend.position = "bottom"
  ) +
  ylim(min(combined_performance$RMSE_Test), max(combined_performance$RMSE_Train))

# Create random forest plot
rf_plot <- ggplot(rf_performance, aes(x = Complexity)) +
  geom_line(aes(y = RMSE_Train, color = "Training"), size = 1.2) +
  geom_line(aes(y = RMSE_Test, color = "Test"), size = 1.2) +
  geom_point(aes(y = RMSE_Train, color = "Training"), size = 2) +
  geom_point(aes(y = RMSE_Test, color = "Test"), size = 2) +
  scale_x_log10(breaks = c(1, 5, 25, 100, 500, 1000, 2000, 5000)) +
  scale_color_manual(values = c("Training" = "#1F78B4", "Test" = "#E31A1C")) +
  labs(
    title = "Random Forest: No Overfitting with More Trees",
    subtitle = "Training and test RMSE remain close even with many trees",
    x = "Number of Trees (Log Scale)",
    y = "RMSE",
    color = "Dataset"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    plot.subtitle = element_text(size = 10),
    axis.title = element_text(size = 10),
    legend.position = "bottom"
  ) +
  ylim(min(combined_performance$RMSE_Test), max(combined_performance$RMSE_Train))

# Combine plots side by side
grid.arrange(dt_plot, rf_plot, ncol = 2)
```

**Analysis of Overfitting: Decision Trees vs Random Forests**

The side-by-side comparison shows clear differences in how decision trees and random forests handle complexity. As decision trees grow deeper, they start to overfit. The training RMSE drops almost to zero, but test RMSE begins to rise, showing the model is memorizing the data instead of learning real patterns.

Random forests, on the other hand, keep training and test RMSE close together even as the number of trees increases. This strong generalization happens because each tree is trained on a random subset of the data and features, and their averaged predictions reduce bias and variance. In short, random forests avoid overfitting and perform more reliably, which is why theyâ€™re often preferred in real-world predictive modeling.

### 3. Linear Regression vs Random Forest Comparison

```{r}
#| label: linear-regression-comparison
#| echo: false
#| message: false
#| warning: false

# Build linear regression model
lm_model <- lm(SalePrice ~ ., data = train_data)
lm_train_pred <- predict(lm_model, train_data)
lm_test_pred <- predict(lm_model, test_data)

# Calculate linear regression RMSE
lm_train_rmse <- sqrt(mean((train_data$SalePrice - lm_train_pred)^2))
lm_test_rmse <- sqrt(mean((test_data$SalePrice - lm_test_pred)^2))

# Calculate linear regression R-squared
lm_test_r2 <- 1 - sum((test_data$SalePrice - lm_test_pred)^2) / sum((test_data$SalePrice - mean(test_data$SalePrice))^2)
lm_train_r2 <- 1 - sum((train_data$SalePrice - lm_train_pred)^2) / sum((train_data$SalePrice - mean(train_data$SalePrice))^2)

# Create comparison table
comparison_table <- data.frame(
  Model = c("Linear Regression", "Random Forest (1 tree)", "Random Forest (100 trees)", "Random Forest (1000 trees)"),
  Test_RMSE = c(lm_test_rmse, rmse_1_test, rmse_100_test, rmse_1000_test),
  Training_RMSE = c(lm_train_rmse, rmse_1_train, rmse_100_train, rmse_1000_train),
  Test_R_squared = c(lm_test_r2, r2_1, r2_100, r2_1000),
  Training_R_squared = c(lm_train_r2, 
                        1 - sum((train_data$SalePrice - predictions_1_train)^2) / sum((train_data$SalePrice - mean(train_data$SalePrice))^2),
                        1 - sum((train_data$SalePrice - predictions_100_train)^2) / sum((train_data$SalePrice - mean(train_data$SalePrice))^2),
                        1 - sum((train_data$SalePrice - predictions_1000_train)^2) / sum((train_data$SalePrice - mean(train_data$SalePrice))^2)),
  Improvement_vs_Linear = c(0, 
                           (lm_test_rmse - rmse_1_test) / lm_test_rmse * 100,
                           (lm_test_rmse - rmse_100_test) / lm_test_rmse * 100,
                           (lm_test_rmse - rmse_1000_test) / lm_test_rmse * 100)
)

# Format the table for better presentation
comparison_table$Test_RMSE <- round(comparison_table$Test_RMSE, 0)
comparison_table$Training_RMSE <- round(comparison_table$Training_RMSE, 0)
comparison_table$Test_R_squared <- round(comparison_table$Test_R_squared, 3)
comparison_table$Training_R_squared <- round(comparison_table$Training_R_squared, 3)
comparison_table$Improvement_vs_Linear <- round(comparison_table$Improvement_vs_Linear, 1)

# Display the comparison table
knitr::kable(comparison_table, 
             caption = "Model Performance Comparison: Linear Regression vs Random Forest",
             col.names = c("Model", "Test RMSE", "Training RMSE", "Test RÂ²", "Training RÂ²", "Improvement vs Linear (%)"),
             align = c("l", "r", "r", "r", "r", "r"),
             format = "html")
```

**Analysis: When Are Random Forests Worth the Complexity?**

The comparison highlights the trade-offs between simplicity and performance. Moving from linear regression to a 100-tree random forest reduces test RMSE by 23.4%, from \$58,234 to \$44,605, offering a meaningful accuracy boost with strong business value. Increasing to 1000 trees adds only a small 2% improvement, suggesting 100 trees is the practical balance for this dataset. Random forests excel at capturing complex, non-linear relationships and handling mixed data types, while linear regression remains faster, more interpretable, and better suited for smaller datasets or cases where transparency matters. Overall, for housing price prediction, the 23.4% improvement from random forests justifies the extra complexity, though linear regression is still a reliable, interpretable baseline.